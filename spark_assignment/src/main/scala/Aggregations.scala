package com.knoldus

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
import org.apache.spark.sql.expressions.Window

object Aggregations extends App {
  val spark = SparkSession.builder()
    .appName("Aggregations")
    .master("local[1]")
    .getOrCreate()

  import spark.implicits._

  val data = Seq(
    ("05:49:56.604899", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604900", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604899", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604900", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604899", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604900", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604899", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604900", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604899", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604900", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604899", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604900", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604899", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604908", "10.0.0.3.5001", "10.0.0.2.54880", 2),
    ("05:49:56.604908", "10.0.0.3.5001", "10.0.0.2.54880", 2),
    ("05:49:56.604908", "10.0.0.3.5001", "10.0.0.2.54880", 2),
    ("05:49:56.604908", "10.0.0.3.5001", "10.0.0.2.54880", 2),
    ("05:49:56.604908", "10.0.0.3.5001", "10.0.0.2.54880", 2),
    ("05:49:56.604908", "10.0.0.3.5001", "10.0.0.2.54880", 2),
    ("05:49:56.604908", "10.0.0.3.5001", "10.0.0.2.54880", 2))

  val dataFrame = data.toDF("column0", "column1", "column2", "label")
  dataFrame.show(false)

  val windowSpec = Window.partitionBy("column1")

  dataFrame.withColumn("count", count("column1").over(windowSpec)).show(false)

}
